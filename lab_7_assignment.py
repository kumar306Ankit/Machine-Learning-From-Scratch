# -*- coding: utf-8 -*-
"""LAB_7_Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fb6NSTQDkKRfhP5rvWIkcijbd2bXNM4O

# QUESTION 1

In 1990 David, Sterling and Wray Buntine donated an Annealing Dataset in order to study Steel Annealing(a heat treatment that alters the physical and sometimes chemical properties of a material). Classes (1,2,3,4,5,U) hereby act as Label and other parameters as Input Features
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.preprocessing import StandardScaler as stdscaler
from sklearn.impute import SimpleImputer as SI

"""## Part 1 and Part 2

From the given link, download “anneal.data”, “anneal.names” and “anneal.test”, convert them into a readable format (Ex: txt, csv, etc....) and do meaningful Exploratory Data Analysis.

Preprocess the data (If any discrepancies/errors, handle them as well) and split the data into [65:35]. [4 + 1 Marks]. There are two subparts here. You need to write in the report about the difference in the observations and explain it if any.: 

● Perform feature standardization and use the standardized data for the rest of the questions 

● Do not perform feature standardization and use the original data for the rest of the questions.
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

class preprocess:
  def __init__(self,data):
    self.data = data
  def nullvalue(self):
    from sklearn.impute import SimpleImputer
    for i in range(len(self.data.columns)): 
        if self.data.iloc[:,i].dtype==object:
            imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
            imputer.fit(self.data.iloc[:,i:i+1])
            self.data.iloc[:,i:i+1] = imputer.transform(self.data.iloc[:,i:i+1])
        else:
          imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
          imputer.fit(self.data.iloc[:,i:i+1])
          self.data.iloc[:,i:i+1] = imputer.transform(self.data.iloc[:,i:i+1])
  def encoding(self):
    from sklearn.preprocessing import LabelEncoder
    for i in self.data.columns: 
        if self.data[i].dtype==object:
            le = LabelEncoder()
            self.data[i] = le.fit_transform(self.data[i])
  def split(self,train,test):
    from sklearn.model_selection import train_test_split
    self.train = train
    self.X = self.data.iloc[:,:-1]
    self.y = self.data.iloc[:,-1]
    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, random_state=42, train_size = self.train)
    return self.X,self.y,self.X_train, self.X_test, self.y_train, self.y_test
  def normalization(self,X1,X2):
    from sklearn.preprocessing import StandardScaler
    sc = StandardScaler()
    X1= sc.fit_transform(X1)
    X2 = sc.transform(X2)
    return X1,X2

data_df = pd.read_csv('/content/anneal.data')
test_df = pd.read_csv('/content/anneal.test')
data_df

cols_to_drop = [col for col in data_df.columns if '?' in col]
data_df = data_df.drop(columns=cols_to_drop)
cols_to_drop = [col for col in test_df.columns if '?' in col]
test_df = test_df.drop(columns=cols_to_drop)
data_df

D = preprocess(data_df)
D.encoding()
X1,y1,X_train, X_test, y_train, y_test = D.split(0.65,0.35)
D1 = preprocess(test_df)
D1.encoding()
X1

data_df.isnull().sum()

print(data_df.duplicated().sum())
data_df.drop_duplicates(inplace=True)

data_df.describe()

data_df.hist(bins=10, figsize=(15, 15))
plt.show()

D = preprocess(data_df)
X1_sc,y1_sc,X_train_sc, X_test_sc, y_train_sc, y_test_sc = D.split(0.65,0.35)
X_train_sc

"""## Part 3

Train 2-3 Classification Models (studied and implemented so far out of which one has to be SVM classifier) with the proper reasoning of choosing them and showing 5-Fold Cross-Validation Plots as well for comparison.

### Before PCA

without standardization

Decision tree regression : I choose this becuase it is a very good model and is simple to understand and can handle both numrerical and categorical data
"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score

def evaluate(X_train, y_train, X_valid, y_valid):
  regressor = DecisionTreeClassifier(random_state = 0)
  regressor.fit(X_train, y_train)
  y_pred = regressor.predict(X_valid)
  return accuracy_score(y_valid, y_pred)

evaluate(X_train, y_train, X_test, y_test)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1)
l = []
x = []
for train_index, test_index in MODEL2.split(X1):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1.iloc[train_index,:]), np.array(X1.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  acc = evaluate(X_train_copy, y_train_copy, X_test_copy, y_test_copy)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For Decission Tree classifier')
plt.show()

"""SVM classifier : """

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svm = SVC()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1)
l = []
x = []
for train_index, test_index in MODEL2.split(X1):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1.iloc[train_index,:]), np.array(X1.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  svm = SVC()
  svm.fit(X_train_copy, y_train_copy)
  y_pred = svm.predict(X_test_copy)
  acc = accuracy_score(y_test_copy, y_pred)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For SVM')
plt.show()

"""with Standardization"""

scale = stdscaler()                 #Using StandardScaler for Scaling and Standardization.
a = np.array(X_train_sc['0.700']).reshape(-1,1)
X_train_sc['0.700'] = scale.fit_transform(a)
b = np.array(X_train_sc['0610.0']).reshape(-1,1)
X_train_sc['0610.0'] = scale.fit_transform(b)
c = np.array(X_train_sc['0000']).reshape(-1,1)
X_train_sc['0000'] = scale.fit_transform(c)
d = np.array(X_train_sc['A']).reshape(-1,1)
X_train_sc.shape
e = np.array(X_train_sc['A']).reshape(-1,1)
X_train_sc['A'] = scale.fit_transform(e)
f = np.array(X_train_sc['08']).reshape(-1,1)
X_train_sc['08'] = scale.fit_transform(f)
g = np.array(X_train_sc['000']).reshape(-1,1)
X_train_sc['000'] = scale.fit_transform(g)

X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train_sc, y_train_sc,train_size = 0.65)

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score

def evaluate(X_train, y_train, X_valid, y_valid):
  regressor = DecisionTreeClassifier(random_state = 0)
  regressor.fit(X_train, y_train)
  y_pred = regressor.predict(X_valid)
  return accuracy_score(y_valid, y_pred)

evaluate(X_train1, y_train1, X_test1, y_test1)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1)
scale = stdscaler()                 #Using StandardScaler for Scaling and Standardization.
a = np.array(X1_sc['0.700']).reshape(-1,1)
X1_sc['0.700'] = scale.fit_transform(a)
b = np.array(X1_sc['0610.0']).reshape(-1,1)
X1_sc['0610.0'] = scale.fit_transform(b)
c = np.array(X1_sc['0000']).reshape(-1,1)
X1_sc['0000'] = scale.fit_transform(c)
d = np.array(X1_sc['A']).reshape(-1,1)
X1_sc.shape
e = np.array(X1_sc['A']).reshape(-1,1)
X1_sc['A'] = scale.fit_transform(e)
f = np.array(X1_sc['08']).reshape(-1,1)
X1_sc['08'] = scale.fit_transform(f)
g = np.array(X1_sc['000']).reshape(-1,1)
X1_sc['000'] = scale.fit_transform(g)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_sc):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_sc.iloc[train_index,:]), np.array(X1_sc.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  acc = evaluate(X_train_copy, y_train_copy, X_test_copy, y_test_copy)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For Decission Tree classifier')
plt.show()

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svm = SVC()
svm.fit(X_train1, y_train1)
y_pred = svm.predict(X_test1)
acc = accuracy_score(y_test1, y_pred)
print("Accuracy:", acc)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_sc):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_sc.iloc[train_index,:]), np.array(X1_sc.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  svm = SVC()
  svm.fit(X_train_copy, y_train_copy)
  y_pred = svm.predict(X_test_copy)
  acc = accuracy_score(y_test_copy, y_pred)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For SVM')
plt.show()

"""here i trained two models- decision tree regressor and svm model both with and without standardization.

## Part 4

Implement Principal Component Analysis from scratch, with sub-tasks as following:- [5 + 10 Marks]a. Centralize the Data via feature-wise means and standard deviations. Write the code for deriving the covariance matrix from scratch. b. Compute Eigenvectors, Eigenvalues and Principal Components and comment on what is the role of eigenvectors in the report. You may use sklearn to find the eigenvectors but others are to be found from scratch.

### PCA FROM SCRATCH

● Do not perform feature standardization and use the original data for the rest of the
questions.
"""

class pca:
  def __init__(self,n=None):                         #Constructor for initializng variables for input. 
    self.n = n                                       # n = No. of Components

  def covmat(self,X):  
    X_centered = X - np.mean(X, axis=0)  # Compute the covariance matrix using matrix multiplication
    self.C = X_centered.T.dot(X_centered) / (X.shape[0] - 1)
    self.X = X_centered
    return self.C
  def fit(self):
    covariance_matrix = self.C
    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix) # Compute the eigenvalues and eigenvectors using numpy.linalg.eig
    self.eigenvalues_dp = [] 
    self.vector = []
    l = []
    for i in range(len(eigenvectors)): # Compute the eigenvalues using the dot product method
        v = eigenvectors[:, i]
        eigenvalue_dp = np.dot(v.T, np.dot(covariance_matrix, v)) / np.dot(v.T, v)
        self.eigenvalues_dp.append(eigenvalue_dp)
        self.vector.append(np.array(v))
        l.append((eigenvalue_dp,v))   
    l = sorted(l,reverse = True)
    self.eigenvalues = np.array([i[0] for i in l])
    self.eigvects = np.array([i[1] for i in l]).T    
    P = np.array(self.X)
    if self.n is None:                               # If n = None there will be no change in no. of components.
        self.principal_components = P@(self.eigvects)
    else:
        self.principal_components = P@(self.eigvects[:,:self.n])
    return self.principal_components
  def transform(self,X):
      mat = self.covmat(X)
      principal_comp = self.fit()
      return np.array(principal_comp)

z = pca(3)
a = z.transform(X1)
a

W= PCA(3)
t = W.fit_transform(X1)
t

X1

"""## Part 5

Use the above-made PCA to reduce the data upto a chosen dimension/principal-components. Plot a bar graph to show the change in variance as you increase the no. of components. Along with this, plot a scatter plot to show the direction of the eigenvectors along with the data points(you may choose any 2 features among the reduced dataset).

#### standard deviation centered
"""

def covmat(X): 
    X_centered = (X - np.mean(X, axis=0))/(np.std(X, axis=0) + 0.00001)   # standard deviation centred
    C = X_centered.T.dot(X_centered) / (X.shape[0] - 1)
    X = X_centered
    return C
def Explained_Variance(e1,e2):
  return np.sum(e1)/np.sum(e2)

Explained_Variances = []
I = []
for i in range(2,12):
  import numpy as np
  I.append(i)
  z = pca(i)
  a = z.transform(X1)
  eig_vals_e1, eig_vecs_e1 = np.linalg.eig(covmat(a))
  eig_vals_e2, eig_vecs_e2 = np.linalg.eig(covmat(X1))
  Explained_Variances.append(Explained_Variance(eig_vals_e1,eig_vals_e2))
  i+=1
plt.bar(I,Explained_Variances)
plt.xlabel('Dimensions')
plt.ylabel('Proportion of Explained Variance')
plt.xticks(np.arange(1, i + 1))
plt.title('Explained Variance')
plt.show()

z = pca(2)
a = z.transform(X1)
plt.scatter(a[:, 0], a[:, 1], c=y1)
plt.xlabel('LD1')
plt.ylabel('LD2')
plt.show()

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# create some random 3D data
x = np.random.rand(100)
y = np.random.rand(100)
z = np.random.rand(100)

# create a 3D scatter plot
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(a[:, 0], a[:, 1], y1, c='b', marker='o')

# set axis labels and show the plot
ax.set_xlabel('X Label')
ax.set_ylabel('Y Label')
ax.set_zlabel('Z Label')
plt.show()

"""##### Variation observed by mean centrailized X_centre"""

def covmat(X):  
    X_centered = X - np.mean(X, axis=0)  # Compute the covariance matrix using matrix multiplication
    C = X_centered.T.dot(X_centered) / (X.shape[0] - 1)
    X = X_centered
    return C
def explained_variances(x): # concept of explained variance I follow
  import numpy as np
  cov_mat = np.cov(x.T)
  eig_vals, eig_vecs = np.linalg.eig(cov_mat)
  eig_pairs = [(eig_vals[i], eig_vecs[:, i]) for i in range(len(eig_vals))]
  eig_pairs.sort(key=lambda x: x[0], reverse=True)
  tot = sum(eig_vals)
  explained_variances = [(i / tot) for i in sorted(eig_vals, reverse=True)]
  return explained_variances

Explained_Variances = []
I = []
for i in range(2,12):
  import numpy as np
  I.append(i)
  z = pca(i)
  a = z.transform(X1)
  s = sum(z.eigenvalues[:z.n])/sum(z.eigenvalues) 
  Explained_Variances.append(s) 
  i+=1
plt.bar(I,Explained_Variances)
plt.xlabel('Principal component')
plt.ylabel('Proportion of variance explained')
plt.xticks(np.arange(1, i + 1))
plt.title('variance explained')
plt.show()

for i in range(2,12):
  z = pca(i)
  a = z.transform(X1)
  e = z.eigvects[:,:i]
  print('For n_component:',i,'\n')
  plt.bar(range(1, i + 1), explained_variances(a))
  plt.xlabel('Principal component')
  plt.ylabel('Proportion of variance explained')
  plt.xticks(np.arange(1, i + 1))
  plt.title('variance explained')
  plt.show()
  for j in range(1,i):
    z = j
    plt.scatter(a[:, 0], a[:, j])
    plt.xlabel('Principal component 1')
    plt.ylabel(f"Principal component {z+1}")
    plt.title('scatter plot')
    plt.show()

X1

"""## Part 6

Train 2-3 chosen classification models alongside 5-Fold Cross-Validation Plots.Show the Test results of Classification Models on both types of datasets (Before and After PCA), via 2-3 Evaluation Metrics of choice (Ex:- Accuracy, Sensitivity, F1-Score, etc.) with the proper reasonings

### After PCA

without standrization
"""

from sklearn.metrics import accuracy_score as acc
from sklearn.metrics import f1_score as f1
from sklearn.metrics import recall_score as rec

def evaluate_ypred(X_train, y_train, X_valid, y_valid):
  regressor = DecisionTreeClassifier(random_state = 0)
  regressor.fit(X_train, y_train)
  y_pred = regressor.predict(X_valid)
  return y_pred

z = pca(3)
X1_copy = pd.DataFrame(z.transform(X1.copy()))
X_train_copy1, X_test_copy1, y_train_copy1, y_test_copy1 = train_test_split(X1_copy,y1, train_size=0.65)

evaluate(X_train_copy1, y_train_copy1, X_test_copy1, y_test_copy1)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1)
l = []
x = []
recs,f1s,accs=[],[],[]
for train_index, test_index in MODEL2.split(X1_copy):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_copy.iloc[train_index,:]), np.array(X1_copy.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  acc = evaluate(X_train_copy, y_train_copy, X_test_copy, y_test_copy)
  u = evaluate_ypred(X_train_copy, y_train_copy, X_test_copy, y_test_copy)
  l.append(acc)
  f1s.append(f1(y_test_copy,u,average='macro'))
  recs.append(rec(y_test_copy,u,average='macro'))
  #print('Accuracy for k:',k,'is',acc,'\n')
  #print('F1 Score:',f1s,'\n')
  #print('recall_score',recs,'\n')
  k+=1
print('Accuracy matrix:',l,'\n')
print('F1 Score matrix',f1s,'\n')
print('recall_score matrix',recs,'\n')
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For Decission Tree Regressor')
plt.show()

"""SVM classifier : """

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svm = SVC()
svm.fit(X_train_copy1, y_train_copy1)
y_pred = svm.predict(X_test_copy1)
acc = accuracy_score(y_test_copy1, y_pred)
print("Accuracy:", acc)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1)
l = []
x = []
recs,f1s,accs=[],[],[]
for train_index, test_index in MODEL2.split(X1_copy):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_copy.iloc[train_index,:]), np.array(X1_copy.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  svm = SVC()
  svm.fit(X_train_copy, y_train_copy)
  y_pred = svm.predict(X_test_copy)
  acc = accuracy_score(y_test_copy, y_pred)
  l.append(acc)
  f1s.append(f1(y_test_copy,y_pred,average='macro'))
  recs.append(rec(y_test_copy,y_pred,average='macro'))
  # print('Accuracy for k:',k,'is',acc,'\n')
  # print(f1s,'\n')
  # print(recs,'\n')
  k+=1
print('Accuracy matrix:',l,'\n')
print('F1 Score matrix',f1s,'\n')
print('recall_score matrix',recs,'\n')
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For SVM')
plt.show()

"""After Standadization"""

z = pca(3)
X1_copy11 = pd.DataFrame(z.transform(X1_sc))
X_train_copy111, X_test_copy111, y_train_copy111, y_test_copy111 = train_test_split(X1_copy11,y1_sc, train_size=0.65)

evaluate(X_train_copy111, y_train_copy111, X_test_copy111, y_test_copy111)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1_sc)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy11):
  x.append(k)
  X_train_sc, X_test_sc = np.array(X1_copy11.iloc[train_index,:]), np.array(X1_copy11.iloc[test_index,:])
  y_train_sc, y_test_sc = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  acc = evaluate(X_train_sc, y_train_sc, X_test_sc, y_test_sc)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For Decission Tree Regressor')
plt.show()

"""SVM classifier : """

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svm = SVC()
svm.fit(X_train_sc, y_train_sc)
y_pred = svm.predict(X_test_sc)
acc = accuracy_score(y_test_sc, y_pred)
print("Accuracy:", acc)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1_sc)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy11):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_copy11.iloc[train_index,:]), np.array(X1_copy11.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  svm = SVC()
  svm.fit(X_train_copy, y_train_copy)
  y_pred = svm.predict(X_test_copy)
  acc = accuracy_score(y_test_copy, y_pred)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For SVM')
plt.show()

X1

"""## Part 7

Were any changes observed before and after implementing PCA, with respect to the distribution of the dataset? Also, make any suitable graph through which the optimal number of principal components can be decided for optimal results
"""

accuracies_svm = []
accuracies_dcr = []
l = []
#pca
X1
for n in range(3,12):
    z1  = pca(n)
    l.append(n)
    X_reduced = pd.DataFrame(z1.transform(X1))
    X_train_copy7, X_test_copy7, y_train_copy7, y_test_copy7 = train_test_split(X_reduced, y1, train_size=0.65, random_state=42)
    svm.fit(X_train_copy7, y_train_copy7)
    y_pred = svm.predict(X_test_copy7)
    accuracies_dcr.append(evaluate(X_train_copy7, y_train_copy7, X_test_copy7, y_test_copy7))
    x = 0
    for i in range(len(y_pred)):
      if y_pred[i] == np.array(y_test_copy7)[i]:
        x+=1
    acc = x/len(y_pred)
    accuracies_svm.append(acc)
plt.plot(l, accuracies_svm, label='SVM')
plt.plot(l, accuracies_dcr, label='DTR')
plt.xlabel('Number of components')
plt.ylabel('Accuracy')
plt.title('Accuracy as a function of number of components')
plt.legend()
plt.show()

X1

"""## Part 8

Bonus : Assuming the Naive Bayes assumption, calculate the eigenvector, eigenvalues and principal components. Do part 6 with these new feature vectors and comment on advantages/disadvantages you observed with this assumption
"""

class pca_naive_bayes:
  def __init__(self,n=None):                         #Constructor for initializng variables for input. 
    self.n = n                                       # n = No. of Components

  def covmat(self,X):  
    X_centered = X - np.mean(X, axis=0)
    self.C = np.zeros((X.shape[1],X.shape[1]))
    for i in range(X.shape[1]):
      for j in range(X.shape[1]):
        if i == j:
          self.C[i][j] = (np.array(X.iloc[:,i]).T).dot(np.array(X.iloc[:,j]))/(X.shape[0] -1)
        else:
          self.C[i][j] = 0
    self.X = X_centered
    return self.C
  def fit(self):
    covariance_matrix = self.C
    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix) # Compute the eigenvalues and eigenvectors using numpy.linalg.eig
    self.eigenvalues_dp = [] 
    self.vector = []
    l = []
    for i in range(len(eigenvectors)): # Compute the eigenvalues using the dot product method
        v = eigenvectors[:, i]
        eigenvalue_dp = np.dot(v.T, np.dot(covariance_matrix, v)) / np.dot(v.T, v)
        self.eigenvalues_dp.append(eigenvalue_dp)
        self.vector.append(np.array(v))
        l.append((eigenvalue_dp,v))   
    l = sorted(l,reverse = True)
    self.eigenvalues = np.array([i[0] for i in l])
    self.eigvects = np.array([i[1] for i in l]).T    
    P = np.array(self.X)
    if self.n is None:                               # If n = None there will be no change in no. of components.
        self.principal_components = P@(self.eigvects)
    else:
        self.principal_components = P@(self.eigvects[:,:self.n])
    return self.principal_components
  def transform(self,X):
      mat = self.covmat(X)
      principal_comp = self.fit()
      return np.array(principal_comp)

z81 = pca_naive_bayes(3)
a81 = z81.transform(X1.copy())
a81

X1

"""### Part 6

without standrization
"""

X1

from sklearn.metrics import accuracy_score as acc
from sklearn.metrics import f1_score as f1
from sklearn.metrics import recall_score as rec

def evaluate_ypred(X_train, y_train, X_valid, y_valid):
  regressor = DecisionTreeClassifier()
  regressor.fit(X_train, y_train)
  y_pred = regressor.predict(X_valid)
  return y_pred

X1

z = pca_naive_bayes(3)
X1_copy82 = pd.DataFrame(z.transform(X1.copy()))
X_train_copy81, X_test_copy81, y_train_copy81, y_test_copy81 = train_test_split(X1_copy82,y1, train_size=0.65)

def evaluate(X_train, y_train, X_valid, y_valid):
  regressor = DecisionTreeClassifier(random_state = 0)
  regressor.fit(X_train, y_train)
  y_pred = regressor.predict(X_valid)
  return accuracy_score(y_valid, y_pred)

X1

evaluate(X_train_copy81, y_train_copy81, X_test_copy81, y_test_copy81)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy82):
  recs,f1s,accs=[],[],[]
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_copy82.iloc[train_index,:]), np.array(X1_copy82.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  acc = evaluate(X_train_copy, y_train_copy, X_test_copy, y_test_copy)
  u = evaluate_ypred(X_train_copy, y_train_copy, X_test_copy, y_test_copy)
  l.append(acc)
  f1s.append(f1(y_test_copy,u,average='macro'))
  recs.append(rec(y_test_copy,u,average='macro'))
  print('Accuracy for k:',k,'is',acc,'\n')
  print(f1s,'\n')
  print(recs,'\n')
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For Decission Tree Regressor')
plt.show()

"""SVM classifier : """

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svm = SVC()
svm.fit(X_train_copy81, y_train_copy81)
y_pred = svm.predict(X_test_copy81)
acc = accuracy_score(y_test_copy81, y_pred)
print("Accuracy:", acc)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy82):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_copy82.iloc[train_index,:]), np.array(X1_copy82.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  svm = SVC()
  svm.fit(X_train_copy, y_train_copy)
  y_pred = svm.predict(X_test_copy)
  acc = accuracy_score(y_test_copy, y_pred)
  l.append(acc)
  f1s.append(f1(y_test_copy,y_pred,average='macro'))
  recs.append(rec(y_test_copy,y_pred,average='macro'))
  print('Accuracy for k:',k,'is',acc,'\n')
  print(f1s,'\n')
  print(recs,'\n')
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For SVM')
plt.show()

"""After Standadization"""

z3 = pca(3)
X1_copy83 = pd.DataFrame(z3.transform(X1_sc.copy()))
X_train_copy831, X_test_copy831, y_train_copy831, y_test_copy831 = train_test_split(X1_copy83,y1_sc, train_size=0.65)

evaluate(X_train_copy831, y_train_copy831, X_test_copy831, y_test_copy831)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1_sc)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy83):
  x.append(k)
  X_train_sc, X_test_sc = np.array(X1_copy83.iloc[train_index,:]), np.array(X1_copy83.iloc[test_index,:])
  y_train_sc, y_test_sc = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  acc = evaluate(X_train_sc, y_train_sc, X_test_sc, y_test_sc)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For Decission Tree Regressor')
plt.show()

"""SVM classifier : """

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svm = SVC()
svm.fit(X_train_copy831, y_train_copy831)
y_pred = svm.predict(X_test_copy831)
acc = accuracy_score(y_test_copy831, y_pred)
print("Accuracy:", acc)

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y1_sc)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy83):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_copy83.iloc[train_index,:]), np.array(X1_copy83.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  svm = SVC()
  svm.fit(X_train_copy, y_train_copy)
  y_pred = svm.predict(X_test_copy)
  acc = accuracy_score(y_test_copy, y_pred)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For SVM')
plt.show()

"""# Question 2

LDA is both a classification algorithm and a dimensionality reduction algorithm. In this question, you have three tasks, 

● Use LDA as a classifier for a classification task

 ● Use LDA as a dimensionality reduction technique and use a classifier of your own choice for the classification task. 
 
 ● Use LDA as a dimensionality reduction technique and compare it with PCA. Perform the aforementioned tasks on the Wine Classification Dataset as instructed below:(You may use any 2 classification techniques of your choice and perform the classification)

### Import Data and Preprocess
"""

wine = pd.read_csv('/content/wine.data',header=None)
wine

wine.isnull().sum()

X = wine.iloc[:,1:14]
y2 = wine.iloc[:,0]

scale = stdscaler()                
for i in X.columns:
  a = np.array(X[i]).reshape(-1,1)
  X[i] = scale.fit_transform(a)

y2.shape

"""## Part 1

Implement Linear Discriminant Analysis from scratch with the following subtasks:- a. A function for computing within class and between class scatter matrices. b. A function that will automatically select the number of linear discriminants based upon the percentage of variance that needs to be conserved

### LDA FROM SCRATCH
"""

class lda:
  def __init__(self,n=None):                         #Constructor for initializng variables for input. 
    self.n = n                                       # n = No. of Components

  def Scaller_withinclass_between_class(self,X,y):
    unique_classes = np.unique(y)
    num_classes = len(unique_classes)
    means = np.array([np.mean(X[y == c], axis=0) for c in np.unique(y)])
    mean_data = np.array([np.mean(X, axis=0)])
    self.SW = np.zeros((X.shape[1],X.shape[1]))
    self.SB = np.zeros((X.shape[1],X.shape[1]))
    for i in range(num_classes):
      X_centered = np.array(X[y==unique_classes[i]] - np.mean(np.array(X[y==unique_classes[i]]), axis=0))  # Compute the covariance matrix using matrix multiplication
      # print("lklk",X_centered)
      self.SW = self.SW + X_centered.T.dot(X_centered)
      #print(self.SW.shape,X_centered.T.dot(X_centered).shape)
      # print(X_centered.T.dot(X_centered))
      X_centeredB = means[i] - mean_data[0]
      num = len(X[y==unique_classes[i]])  # Compute the covariance matrix using matrix multiplication
      self.SB += num*(X_centeredB.T.dot(X_centeredB))
    self.X = X
    self.y = y
    # print(self.SW)
    return self.SW,self.SB
  def fit(self,X,y):
    import pandas as pd
    A = (np.linalg.inv(self.SW)).dot(self.SB)
    covariance_matrix = A
    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix) # Compute the eigenvalues and eigenvectors using numpy.linalg.eig
    self.eigenvalues_dp = [] 
    self.vector = []
    l = []
    for i in range(len(eigenvectors)): # Compute the eigenvalues using the dot product method
        v = eigenvectors[:, i]
        eigenvalue_dp = np.dot(v.T, np.dot(covariance_matrix, v)) / np.dot(v.T, v)
        self.eigenvalues_dp.append(eigenvalue_dp)
        self.vector.append(np.array(v))
        l.append((eigenvalue_dp,v)) 
    l = sorted(l,reverse = True)
    self.eigenvalues = np.array([i[0] for i in l])
    self.eigvects = np.array([i[1] for i in l]).T  
    P = np.array(self.X)
    if self.n is None:                               # If n = None there will be no change in no. of components.
        self.principal_components = P@(self.eigvects)
    else:
        self.principal_components = P@(self.eigvects[:,:self.n])
    return self.principal_components

z = lda(2)
SW,SB = z.Scaller_withinclass_between_class(X,y2)
z.fit(X,y2)

lda1 = LDA(n_components=2)
X_train22 = lda1.fit_transform(X, y2)
X_train22

"""### Checking Accuracy of inbuilt and scratch"""

z = lda(2)
SW,SB = z.Scaller_withinclass_between_class(X,y2)
X1_copy21 = z.fit(X,y2)
X_train_copy21, X_test_copy21, y_train_copy21, y_test_copy21 = train_test_split(X1_copy21,y2, train_size=0.65)
print('Accuracy of Scratch',evaluate(np.real(X_train_copy21), y_train_copy21, np.real(X_test_copy21), y_test_copy21),'\n')
X_train_copy22, X_test_copy22, y_train_copy22, y_test_copy22 = train_test_split(X_train22,y2, train_size=0.65)
print('Accuracy of inbuilt',evaluate(np.real(X_train_copy22), y_train_copy22, np.real(X_test_copy22), y_test_copy22),'\n')

"""## Part 2

Vary the variance and identify features that have a high impact on the classification tasks using LDA and visualize the feature space for the same using those linear discriminants

#### Standard_Deviation
"""

def covmat(X): 
    X_centered = (X - np.mean(X, axis=0))/(np.std(X, axis=0) + 0.00001)   # standard deviation centred
    C = X_centered.T.dot(X_centered) / (X.shape[0] - 1)
    X = X_centered
    return C
def Explained_Variance(e1,e2):
  return np.sum(e1)/np.sum(e2)

Explained_Variances = []
I = []
for i in range(2,12):
  import numpy as np
  I.append(i)
  z = lda(i)
  SW,SB = z.Scaller_withinclass_between_class(X,y2)
  a = z.fit(X,y2)
  eig_vals_e1, eig_vecs_e1 = np.linalg.eig(covmat(a))
  eig_vals_e2, eig_vecs_e2 = np.linalg.eig(covmat(X))
  Explained_Variances.append(Explained_Variance(eig_vals_e1,eig_vals_e2))
  i+=1
plt.bar(I,Explained_Variances)
plt.xlabel('Dimensions')
plt.ylabel('Proportion of Explained Variance')
plt.xticks(np.arange(1, i + 1))
plt.title('Explained Variance')
plt.show()

z = lda(i)
SW,SB = z.Scaller_withinclass_between_class(X,y2)
a = z.fit(X,y2)
plt.scatter(a[:, 0], a[:, 1], c=y2)
plt.xlabel('LD1')
plt.ylabel('LD2')
plt.show()

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# create some random 3D data
x = np.random.rand(100)
y = np.random.rand(100)
z = np.random.rand(100)

# create a 3D scatter plot
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(a[:, 0], a[:, 1], y2, c='b', marker='o')

# set axis labels and show the plot
ax.set_xlabel('X Label')
ax.set_ylabel('Y Label')
ax.set_zlabel('Z Label')
plt.show()

"""#### Variance"""

def explained_variances(x): # concept of explained variance I follow
  import numpy as np
  cov_mat = np.cov(x.T)
  eig_vals, eig_vecs = np.linalg.eig(cov_mat)
  eig_pairs = [(eig_vals[i], eig_vecs[:, i]) for i in range(len(eig_vals))]
  eig_pairs.sort(key=lambda x: x[0], reverse=True)
  tot = sum(eig_vals)
  explained_variances = [(i / tot) for i in sorted(eig_vals, reverse=True)]
  return explained_variances

for i in range(2,12):
  m = lda(i)
  SW,SB = m.Scaller_withinclass_between_class(X,y2)
  a = m.fit(X,y2)
  print('For n_component:',i,'\n')
  plt.bar(range(1, i + 1), explained_variances(a))
  plt.xlabel('Principal component')
  plt.ylabel('Proportion of variance explained')
  plt.xticks(np.arange(1, i + 1))
  plt.title('variance explained')
  plt.show()

m = lda(i)
SW,SB = m.Scaller_withinclass_between_class(X,y2)
a = m.fit(X,y)
plt.scatter(a[:, 0], a[:, 1], c=y2)
plt.xlabel('LD1')
plt.ylabel('LD2')
plt.show()

"""## Part 3

Perform PCA on the dataset and compare the results with LDA by using any 2 classification techniques

After Standadization

### PCA
"""

a = pca(3)
X1_copy23 = pd.DataFrame(a.transform(X))
X_train_copy231, X_test_copy231, y_train_copy231, y_test_copy231 = train_test_split(X1_copy23,y2,train_size=0.65)

"""#### Decision tree"""

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y2)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy23):
  x.append(k)
  X_train_sc, X_test_sc = np.array(X1_copy23.iloc[train_index,:]), np.array(X1_copy23.iloc[test_index,:])
  y_train_sc, y_test_sc = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  acc = evaluate(X_train_sc, y_train_sc, X_test_sc, y_test_sc)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For Decission Tree Regressor')
plt.show()

"""#### SVM classifier : """

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y2)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy23):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_copy23.iloc[train_index,:]), np.array(X1_copy23.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  svm = SVC()
  svm.fit(X_train_copy, y_train_copy)
  y_pred = svm.predict(X_test_copy)
  acc = accuracy_score(y_test_copy, y_pred)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For SVM')
plt.show()

"""### LDA"""

a21 = lda(3)
SW,SB = a21.Scaller_withinclass_between_class(X,y2)
X1_copy24 = pd.DataFrame(np.real(a21.fit(X,y2)))
X_train_copy241, X_test_copy241, y_train_copy241, y_test_copy241 = train_test_split(X1_copy24,y2,train_size=0.65)

"""#### Decision tree"""

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y2)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy24):
  x.append(k)
  X_train_sc, X_test_sc = np.array(X1_copy24.iloc[train_index,:]), np.array(X1_copy24.iloc[test_index,:])
  y_train_sc, y_test_sc = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  acc = evaluate(X_train_sc, y_train_sc, X_test_sc, y_test_sc)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For Decission Tree Regressor')
plt.show()

"""#### SVM classifier : """

from sklearn.model_selection import KFold
n = 5
k=1
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y)
l = []
x = []
for train_index, test_index in MODEL2.split(X1_copy24):
  x.append(k)
  X_train_copy, X_test_copy = np.array(X1_copy24.iloc[train_index,:]), np.array(X1_copy24.iloc[test_index,:])
  y_train_copy, y_test_copy = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
  svm = SVC()
  svm.fit(X_train_copy, y_train_copy)
  y_pred = svm.predict(X_test_copy)
  acc = accuracy_score(y_test_copy, y_pred)
  l.append(acc)
  print('Accuracy for k:',k,'is',acc)
  k+=1
print("Average accuracy for 5fold Cross Validation:",np.mean(l))
plt.plot(x,l)
plt.xlabel('k')
plt.ylabel('Accuracy For SVM')
plt.show()

"""## Part 4

Create a table to properly note down the accuracies in case of each classifier and the corresponding reduction technique. Show using scatter plot of any two features among the features you chose which contribute to the maximum variance the decision boundary in case of LDA.
"""

m = lda(2)
SW,SB = m.Scaller_withinclass_between_class(X,y2)
a = m.fit(X,y2)
plt.scatter(a[:, 0], a[:, 1], c=y2)
plt.xlabel('LD1')
plt.ylabel('LD2')
plt.show()

"""## Part 5

Using LDA as a classifier, perform 5-fold cross-validation and plot ROC and compute AUC for each fold from scratch
"""

a21 = lda(3)
SW,SB = a21.Scaller_withinclass_between_class(X,y2)
X1_copy24 = pd.DataFrame(np.real(a21.fit(X,y2)))
X_train_copy241, X_test_copy241, y_train_copy241, y_test_copy241 = train_test_split(X1_copy24,y2,train_size=0.65)

from sklearn.model_selection import KFold
n = 5
k=3
MODEL2 = KFold(n_splits=n, shuffle=True)
accuracies = []
y=pd.DataFrame(y2)
for train_index, test_index in MODEL2.split(X1_copy24):
    X_train, X_test = np.array(X1_copy24.iloc[train_index,:]), np.array(X1_copy24.iloc[test_index,:])
    y_train, y_test = np.array(y.iloc[train_index,:]), np.array(y.iloc[test_index,:])
    y_pred1= evaluate_ypred(X_train, y_train, X_test, y_test)
    y_test=y_test.reshape(1,-1)[0]
    p = np.array(y_test)
    accuracies.append(((y_pred1 == p).sum())/len(y_test))
# Calculate the mean Accuracy score across all iterations
mean_acc = np.mean(accuracies)
print("Mean Accuracy:", mean_acc)

y_pred1= evaluate_ypred(X_train_copy241, y_train_copy241, X_test_copy241, y_test_copy241)
y_test_copy241 = np.array(y_test_copy241).reshape(1,-1)[0]
p = np.array(y_test_copy241)

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LogisticRegression
import numpy as np
# In muliti class Convert labels to binary format
y_bin = label_binarize(y_test_copy241.copy(), classes=[0, 1, 2, 3])
y_pred = label_binarize(y_pred1.copy(), classes=[0, 1, 2, 3])
# Compute the micro-averaged ROC curve and AUC score
fpr, tpr, _ = roc_curve(y_bin.ravel(), y_pred.ravel())
roc_auc = auc(fpr, tpr)
# Plot the ROC curve
import matplotlib.pyplot as plt
plt.figure()
plt.plot(fpr, tpr, label='Micro-averaged ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Micro-averaged ROC Curve')
plt.legend(loc='lower right')
plt.show()